{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shaoyuming/anaconda3/lib/python3.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
      "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
      "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
      "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
      "\n",
      "   PTRATIO       B  LSTAT  \n",
      "0     15.3  396.90   4.98  \n",
      "1     17.8  396.90   9.14  \n",
      "2     17.8  392.83   4.03  \n",
      "152 152\n",
      "linear regression train score: 0.7419034960343789\n",
      "linear regression test score: 0.7146895989294313\n",
      "ridge regression train score low alpha: 0.7419030253527293\n",
      "ridge regression test score low alpha: 0.7145115044376257\n",
      "ridge regression train score high alpha: 0.7172809669938278\n",
      "ridge regression test score high alpha: 0.6805838894730998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update({'font.size': 12})\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "boston=load_boston()\n",
    "boston_df=pd.DataFrame(boston.data,columns=boston.feature_names)\n",
    "#print boston_df.info()\n",
    "# add another column that contains the house prices which in scikit learn datasets are considered as target\n",
    "boston_df['Price']=boston.target\n",
    "#print boston_df.head(3)\n",
    "newX=boston_df.drop('Price',axis=1)\n",
    "print(newX[0:3]) # check \n",
    "newY=boston_df['Price']\n",
    "\n",
    "#print type(newY)# pandas core frame\n",
    "X_train,X_test,y_train,y_test=train_test_split(newX,newY,test_size=0.3,random_state=3)\n",
    "print (len(X_test), len(y_test))\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "rr = Ridge(alpha=0.01) # higher the alpha value, more restriction on the coefficients; low alpha > more generalization, coefficients are barely\n",
    "# restricted and in this case linear and ridge regression resembles\n",
    "rr.fit(X_train, y_train)\n",
    "\n",
    "rr100 = Ridge(alpha=100) #  comparison with alpha value\n",
    "rr100.fit(X_train, y_train)\n",
    "\n",
    "train_score=lr.score(X_train, y_train)\n",
    "test_score=lr.score(X_test, y_test)\n",
    "Ridge_train_score = rr.score(X_train,y_train)\n",
    "Ridge_test_score = rr.score(X_test, y_test)\n",
    "Ridge_train_score100 = rr100.score(X_train,y_train)\n",
    "Ridge_test_score100 = rr100.score(X_test, y_test)\n",
    "print (\"linear regression train score:\", train_score)\n",
    "print (\"linear regression test score:\", test_score)\n",
    "print (\"ridge regression train score low alpha:\", Ridge_train_score)\n",
    "print (\"ridge regression test score low alpha:\", Ridge_test_score)\n",
    "print (\"ridge regression train score high alpha:\", Ridge_train_score100)\n",
    "print (\"ridge regression test score high alpha:\", Ridge_test_score100)\n",
    "plt.plot(rr.coef_,alpha=0.7,linestyle='none',marker='*',markersize=5,color='red',label=r'Ridge; $\\alpha = 0.01$',zorder=7) # zorder for ordering the markers\n",
    "plt.plot(rr100.coef_,alpha=0.5,linestyle='none',marker='d',markersize=6,color='blue',label=r'Ridge; $\\alpha = 100$') # alpha here is for transparency\n",
    "plt.plot(lr.coef_,alpha=0.4,linestyle='none',marker='o',markersize=7,color='green',label='Linear Regression')\n",
    "plt.xlabel('Coefficient Index',fontsize=16)\n",
    "plt.ylabel('Coefficient Magnitude',fontsize=16)\n",
    "plt.legend(fontsize=13,loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# difference of lasso and ridge regression is that some of the coefficients can be zero i.e. some of the features are \n",
    "# completely neglected\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "#print cancer.keys()\n",
    "cancer_df = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "#print cancer_df.head(3)\n",
    "X = cancer.data\n",
    "Y = cancer.target\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y, test_size=0.3, random_state=31)\n",
    "lasso = Lasso() # default alpha=1\n",
    "lasso.fit(X_train,y_train)\n",
    "train_score=lasso.score(X_train,y_train)\n",
    "test_score=lasso.score(X_test,y_test)\n",
    "\n",
    "\n",
    "lasso001 = Lasso(alpha=0.01, max_iter=10e5)\n",
    "lasso001.fit(X_train,y_train)\n",
    "train_score001=lasso001.score(X_train,y_train)\n",
    "test_score001=lasso001.score(X_test,y_test)\n",
    "\n",
    "\n",
    "lasso00001 = Lasso(alpha=0.0001, max_iter=10e5)\n",
    "lasso00001.fit(X_train,y_train)\n",
    "train_score00001=lasso00001.score(X_train,y_train)\n",
    "test_score00001=lasso00001.score(X_test,y_test)\n",
    "coeff_used00001 = np.sum(lasso00001.coef_!=0)\n",
    "\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "lr_train_score=lr.score(X_train,y_train)\n",
    "lr_test_score=lr.score(X_test,y_test)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
